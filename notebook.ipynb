{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 3 - ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mice_eeg = pd.read_csv('./pw3_data/EEG_mouse_data_1.csv')\n",
    "mice_eeg2 = pd.read_csv('./pw3_data/EEG_mouse_data_2.csv')\n",
    "df = pd.concat([mice_eeg, mice_eeg2], ignore_index=True)\n",
    "\n",
    "mice_eeg3 = pd.read_csv('./pw3_data/EEG_mouse_data_test.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the first 25 features as they are contain the biggest occurences count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df.iloc[:, 1:26].to_numpy()\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "# df.sample(frac=1) #TODO: obsolete because of KFold ?\n",
    "\n",
    "# Cut in 3 folds (1/3 for test and 2/3 for training)\n",
    "# shuffle d'abord avant de dÃ©couper\n",
    "#  normaliser tout fit\n",
    "# partager\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "\n",
    "pl.clf()\n",
    "\n",
    "keras.utils.set_random_seed(123)\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df)):\n",
    "    print(str(i) + ' ' + str(train_index) + ' ' + str(test_index))\n",
    "# See training 2 cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and setup our MLP\n",
    "# Source: From the notebook 5. See 'Changed: '\n",
    "def create_model():\n",
    "  mlp = keras.Sequential([\n",
    "      layers.Input(shape=(25,)), # Changed: shape=(25,) instead of 2\n",
    "      layers.Dense(4, activation=\"tanh\"), # Try different numbers of hidden neurons here (e.g. 2, 4, 8, 32, 128)\n",
    "      # Changed: todo try to change the amount of layers and perceptrons per layer\n",
    "      layers.Dense(1, activation=\"tanh\"),   # next \n",
    "  ])\n",
    "\n",
    "  # Experiment with hyperparameters here:\n",
    "  # momentum: [0, 0.8, 0.9, 0.99]\n",
    "  # learning_rate: [0.1, 0.01, 0.001, 0.0001]\n",
    "  mlp.compile(\n",
    "      optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.99),\n",
    "      loss=\"mse\",\n",
    "  )\n",
    "\n",
    "  return mlp\n",
    "\n",
    "mlp = create_model()\n",
    "mlp.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with first column \"state\" and replace n with 1 and other values with -1, \n",
    "# convert it as numpy array to access rows and not columns\n",
    "output_data = df.iloc[:,0].map(lambda e: 1 if e == 'n' else -1).to_numpy()\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training on 3 folds\n",
    "history_list = []\n",
    "trained_mlp = []\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "print(output_data.shape)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(input_data)):\n",
    "  print(str(i) + ' ' + str(train_index) + ' ' + str(test_index))\n",
    "  \n",
    "  # We need to create a new model everytime otherwise fit will continue previous training\n",
    "  mlp = create_model()\n",
    "  \n",
    "  train_input = scaler.fit_transform(input_data[train_index])\n",
    "  test_input = scaler.fit_transform(input_data[test_index])\n",
    "  \n",
    "  history = mlp.fit(\n",
    "      x=train_input, \n",
    "      y=output_data[train_index],\n",
    "      validation_data=(test_input, output_data[test_index]),\n",
    "      epochs=3\n",
    "  )\n",
    "\n",
    "  history_list.append(history)\n",
    "  trained_mlp.append(mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_mlp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_losses = np.array([history.history['loss'] for history in history_list])\n",
    "val_losses = np.array([history.history['val_loss'] for history in history_list])\n",
    "\n",
    "# Calculate mean and standard deviation for training and validation losses\n",
    "mean_train_loss = np.mean(train_losses, axis=0)\n",
    "std_train_loss = np.std(train_losses, axis=0)\n",
    "mean_val_loss = np.mean(val_losses, axis=0)\n",
    "std_val_loss = np.std(val_losses, axis=0)\n",
    "\n",
    "# Plot mean and standard deviation for training loss\n",
    "pl.plot(mean_train_loss, label='Training Loss (Mean)')\n",
    "pl.fill_between(range(len(mean_train_loss)), mean_train_loss - std_train_loss, mean_train_loss + std_train_loss, alpha=0.3, label='Training Loss (Std)')\n",
    "\n",
    "# Plot mean and standard deviation for validation loss\n",
    "pl.plot(mean_val_loss, label='Validation Loss (Mean)')\n",
    "pl.fill_between(range(len(mean_val_loss)), mean_val_loss - std_val_loss, mean_val_loss + std_val_loss, alpha=0.3, label='Validation Loss (Std)')\n",
    "\n",
    "# Add labels and legend\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Loss')\n",
    "pl.legend()\n",
    "\n",
    "# Display the plot\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model in enumerate(trained_mlp):\n",
    "    # Plot model's output in the feature space\n",
    "    input_x = np.arange(-1.2, 1.2, 0.1)\n",
    "    input_y = np.arange(-1.2, 1.2, 0.1)\n",
    "    input_x_matrix, input_y_matrix = np.meshgrid(input_x, input_y)\n",
    "    inputs_xy = np.concatenate((input_x_matrix.flatten()[:,np.newaxis], input_y_matrix.flatten()[:,np.newaxis]), axis=1)\n",
    "\n",
    "    output_values = model(inputs_xy)\n",
    "    output_matrix = np.reshape(output_values, input_x_matrix.shape)\n",
    "\n",
    "    pl.figure(figsize=(8,8))\n",
    "    img = pl.imshow(np.flipud(output_matrix), interpolation='None', extent=(-1.2,1.2,-1.2,1.2), cmap=\"turbo\")\n",
    "    pl.colorbar(img, shrink=0.7)\n",
    "    pl.scatter(input_data[:,0], input_data[:,1], c=[(['b', 'r'])[int(d>0)] for d in output_data], s=100, edgecolors='black')\n",
    "    pl.title(f'MLP {idx+1} feature space output')\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note for later: next section will use 3 instead of 1 because 3 classes, and ~ supermax \n",
    "layers.Dense(1, activation=\"tanh\"),   # next \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
