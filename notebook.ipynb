{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 3 - ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mice_eeg = pd.read_csv('./pw3_data/EEG_mouse_data_1.csv')\n",
    "mice_eeg2 = pd.read_csv('./pw3_data/EEG_mouse_data_2.csv')\n",
    "df = pd.concat([mice_eeg, mice_eeg2], ignore_index=True)\n",
    "\n",
    "mice_eeg3 = pd.read_csv('./pw3_data/EEG_mouse_data_test.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the first 25 features as they are contain the biggest occurences count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, 1:26]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize\n",
    "dfn = scaler.fit(df)\n",
    "\n",
    "# Shuffle\n",
    "# df.sample(frac=1) #TODO: obsolete because of KFold ?\n",
    "\n",
    "# Cut in 3 folds (1/3 for test and 2/3 for training)\n",
    "# shuffle d'abord avant de d√©couper\n",
    "#  normaliser tout fit\n",
    "# partager\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "\n",
    "pl.clf()\n",
    "\n",
    "keras.utils.set_random_seed(123)\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df)):\n",
    "    print(str(i) + ' ' + str(train_index) + ' ' + str(test_index))\n",
    "# See training 2 cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and setup our MLP\n",
    "# Source: From the notebook 5. See 'Changed: '\n",
    "def create_model():\n",
    "  mlp = keras.Sequential([\n",
    "      layers.Input(shape=(25,)), # Changed: shape=(25,) instead of 2\n",
    "      layers.Dense(2, activation=\"tanh\"), # Try different numbers of hidden neurons here (e.g. 2, 4, 8, 32, 128)\n",
    "      # Changed: todo try to change the amount of layers and perceptrons per layer\n",
    "      layers.Dense(1, activation=\"tanh\"),   # next \n",
    "  ])\n",
    "\n",
    "  # Experiment with hyperparameters here:\n",
    "  # momentum: [0, 0.8, 0.9, 0.99]\n",
    "  # learning_rate: [0.1, 0.01, 0.001, 0.0001]\n",
    "  mlp.compile(\n",
    "      optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.99),\n",
    "      loss=\"mse\",\n",
    "  )\n",
    "\n",
    "  return mlp\n",
    "\n",
    "mlp = create_model()\n",
    "mlp.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training on 3 folds\n",
    "history_list = []\n",
    "trained_mlp = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df)):\n",
    "  print(str(i) + ' ' + str(train_index) + ' ' + str(test_index))\n",
    "  # We need to create a new model everytime otherwise fit will continue previous training\n",
    "  mlp = create_model()\n",
    "\n",
    "  history = mlp.fit(\n",
    "      x=input_data[train_index], y=output_data[train_index],\n",
    "      validation_data=(df[test_index], output_data[test_index]),\n",
    "      epochs=400\n",
    "  )\n",
    "\n",
    "  history_list.append(history)\n",
    "  trained_mlp.append(mlp)\n",
    "\n",
    "# TODO: fix this bug with input data and output data, how to use them ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note for later: next section will use 3 instead of 1 because 3 classes, and ~ supermax \n",
    "layers.Dense(1, activation=\"tanh\"),   # next \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
